{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ec5ae0",
   "metadata": {},
   "source": [
    "# Computing Graphs and initial conditions\n",
    "\n",
    "This notebook will instatiate and save the necessities for conducting the dynamical analysis.\n",
    "Firstly the dataset will be elaborated and then graphs and initial conditions will be computed.\n",
    "Might be necessary to change the data path (`PATH_TO_DATA`) or the dataset filnames (`WORD_VECTORS_FILENAME` and `ARTCLES_DF_FILENAME`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5747b823-cf56-4939-b9d5-8c86e64c94ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T16:30:02.566159Z",
     "start_time": "2022-01-08T16:30:02.205349Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import normalize\n",
    "from gensim.models.word2vec import KeyedVectors\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "# import cugraph ## this library works with CUDA-capable GPUs but has many issues\n",
    "\n",
    "PATH_TO_DATA = Path('../data')\n",
    "WORD_VECTORS_FILENAME = 'words_dataframe.csv'\n",
    "ARTICLES_DF_FILENAME = 'info_dataframe.csv'\n",
    "N_THREADS = 64\n",
    "MIN_SIM = 0.75\n",
    "TIME_THRESHOLD = 18*24 # in hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49565de-1bd6-44ef-aae8-55ad2dedd36c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Similarity Matrix\n",
    "\n",
    "In order to create the **Similarity Matrix**, we should _load_ the 'WORD VECTORS' DataFrame and then we should _calculate the distances_ of all the articles (exploiting the simple dot product).\n",
    "'WORD_VECTORS' must be passed through the `create_model_matrix` function that will map each document to its 300-dim vector representation using a model from `gensim`.\n",
    "This model can be dowloaded using the downloading API of `gensim`, more information can be found [here](https://github.com/RaRe-Technologies/gensim-data).\n",
    "The available models to choose are [ConceptNet Numberbatch](https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972) or [Google News Word2Vec](https://code.google.com/archive/p/word2vec/).\n",
    "\n",
    "The results of `create_model_matrix` must be normalized before computing the distance.\n",
    "The fastest method for normalization is that from _sklearn_, but also a _numpy_ version is provided (but not used).\n",
    "\n",
    "This is equivalent to use the _cosine similarity_ distance to compute these distances.\n",
    "\n",
    "Loading the DataFrame is the first thing to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd44b9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24467/3706815515.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  word_vectors = pd.read_csv(PATH_TO_DATA/WORD_VECTORS_FILENAME).drop(['Unnamed: 0','article_id'], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>igor</th>\n",
       "      <th>flag</th>\n",
       "      <th>few</th>\n",
       "      <th>repeat</th>\n",
       "      <th>confeder</th>\n",
       "      <th>drill</th>\n",
       "      <th>januari</th>\n",
       "      <th>bobic</th>\n",
       "      <th>situat</th>\n",
       "      <th>parti</th>\n",
       "      <th>...</th>\n",
       "      <th>sisk</th>\n",
       "      <th>klfi</th>\n",
       "      <th>thurman</th>\n",
       "      <th>bronlynn</th>\n",
       "      <th>gar</th>\n",
       "      <th>ujima</th>\n",
       "      <th>wksu</th>\n",
       "      <th>wkyc</th>\n",
       "      <th>akron</th>\n",
       "      <th>artsnow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2992 rows × 59010 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      igor  flag  few  repeat  confeder  drill  januari  bobic  situat  parti  \\\n",
       "0      0.0   0.0  0.0     0.0       0.0    0.0      1.0    0.0     0.0    0.0   \n",
       "1      0.0   0.0  1.0     0.0       0.0    0.0      0.0    0.0     0.0    1.0   \n",
       "2      0.0   0.0  0.0     0.0       0.0    0.0      0.0    0.0     0.0    1.0   \n",
       "3      0.0   0.0  0.0     0.0       0.0    0.0      0.0    0.0     0.0    0.0   \n",
       "4      0.0   0.0  0.0     1.0       0.0    0.0      0.0    0.0     0.0    2.0   \n",
       "...    ...   ...  ...     ...       ...    ...      ...    ...     ...    ...   \n",
       "2987   0.0   0.0  0.0     0.0       0.0    0.0      0.0    0.0     0.0    0.0   \n",
       "2988   0.0   2.0  0.0     0.0       0.0    0.0      0.0    0.0     0.0    0.0   \n",
       "2989   0.0   0.0  0.0     0.0       0.0    0.0      0.0    0.0     0.0    0.0   \n",
       "2990   0.0   0.0  0.0     0.0       0.0    0.0      0.0    0.0     0.0    0.0   \n",
       "2991   0.0   0.0  0.0     0.0       0.0    0.0      0.0    0.0     0.0    0.0   \n",
       "\n",
       "      ...  sisk  klfi  thurman  bronlynn  gar  ujima  wksu  wkyc  akron  \\\n",
       "0     ...   0.0   0.0      0.0       0.0  0.0    0.0   0.0   0.0    0.0   \n",
       "1     ...   0.0   0.0      0.0       0.0  0.0    0.0   0.0   0.0    0.0   \n",
       "2     ...   0.0   0.0      0.0       0.0  0.0    0.0   0.0   0.0    0.0   \n",
       "3     ...   0.0   0.0      0.0       0.0  0.0    0.0   0.0   0.0    0.0   \n",
       "4     ...   0.0   0.0      0.0       0.0  0.0    0.0   0.0   0.0    0.0   \n",
       "...   ...   ...   ...      ...       ...  ...    ...   ...   ...    ...   \n",
       "2987  ...   0.0   0.0      0.0       0.0  0.0    0.0   0.0   0.0    0.0   \n",
       "2988  ...   0.0   0.0      0.0       0.0  0.0    0.0   0.0   0.0    0.0   \n",
       "2989  ...   0.0   0.0      0.0       0.0  0.0    0.0   0.0   0.0    0.0   \n",
       "2990  ...   0.0   0.0      0.0       0.0  0.0    0.0   0.0   0.0    0.0   \n",
       "2991  ...   0.0   0.0      0.0       0.0  0.0    0.0   0.0   0.0    0.0   \n",
       "\n",
       "      artsnow  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "...       ...  \n",
       "2987      0.0  \n",
       "2988      0.0  \n",
       "2989      0.0  \n",
       "2990      0.0  \n",
       "2991      0.0  \n",
       "\n",
       "[2992 rows x 59010 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataframe\n",
    "word_vectors = pd.read_csv(PATH_TO_DATA/WORD_VECTORS_FILENAME).drop(['Unnamed: 0','article_id'], 1)\n",
    "# get all the possible words\n",
    "all_words = list(word_vectors.columns)\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87e1599",
   "metadata": {},
   "source": [
    "Then, the function for creating the whole word matrix is defined, TFITF score is used as weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c9f4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_matrix(data, model):\n",
    "\n",
    "    # instatiate the iterator\n",
    "    articles_iterator = tqdm(\n",
    "        range(len(data)),\n",
    "        leave=False,\n",
    "        unit='articles',\n",
    "    )\n",
    "\n",
    "    # function to parallelize \n",
    "    def fn(article):\n",
    "        article_vector = np.zeros((1, 300))\n",
    "        for i, word in enumerate(all_words):\n",
    "            # using tf-idf as weight\n",
    "            tf = data[article,i]\n",
    "            n = np.sum(data[:,i])\n",
    "            idtf = np.log(len(data)/n)\n",
    "            weight = tf*idtf\n",
    "            try:\n",
    "                word_vector = model.get_vector(word)\n",
    "                try:\n",
    "                    assert np.isfinite(word_vector).all()\n",
    "                except AssertionError:\n",
    "                    print(word_vector)\n",
    "            except KeyError:\n",
    "                word_vector = np.zeros((1, 300))\n",
    "            article_vector = article_vector + word_vector*weight\n",
    "        return article_vector\n",
    "            \n",
    "    list_of_docvs = Parallel(n_jobs=N_THREADS)(delayed(fn)(i) for i in articles_iterator)\n",
    "    return np.array(list_of_docvs).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51499d2f",
   "metadata": {},
   "source": [
    "Loading the [ConceptNet Numberbatch](https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972) model, and adapting to our words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca5e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptnet = KeyedVectors.load_word2vec_format(PATH_TO_DATA/'conceptnet-numberbatch-17-06-300.gz')\n",
    "conceptnet = conceptnet.vectors_for_all(all_words)\n",
    "conceptnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f731e9",
   "metadata": {},
   "source": [
    "Loading the [Google News Word2Vec](https://code.google.com/archive/p/word2vec/) model, and adapting to our words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e17e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7fba78e33a30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_word2vec = KeyedVectors.load_word2vec_format(PATH_TO_DATA/'word2vec-google-news-300.gz', binary=True)\n",
    "google_news_word2vec = google_news_word2vec.vectors_for_all(all_words)\n",
    "google_news_word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def882bb",
   "metadata": {},
   "source": [
    "Get the whole word matrix using the DataFrame and the model choosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~1h computations\n",
    "model = conceptnet\n",
    "conceptnet_docvs = create_model_matrix(np.array(word_vectors), model)\n",
    "np.savez(PATH_TO_DATA/'conceptnet_docvs.npz', conceptnet_docvs)\n",
    "conceptnet_docvs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f75ae32-242a-4e28-906d-f1424a1c01d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2992 [00:00<?, ?articles/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2992, 300)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ~1h20min computations\n",
    "model = google_news_word2vec\n",
    "google_docvs = create_model_matrix(np.array(word_vectors), model)\n",
    "np.savez(PATH_TO_DATA/'google_docvs.npz', google_docvs)\n",
    "google_docvs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee17946-503a-4f99-bdfd-091d45c35283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.15124185e+00,  8.49358914e+00,  3.24921606e+00, ...,\n",
       "        -7.54261422e+00,  4.95666061e+00, -2.39626000e+00],\n",
       "       [ 2.14510083e+01,  3.21642291e+01,  5.47439096e+00, ...,\n",
       "        -3.59560750e+01,  1.89494194e+01,  8.06504266e-01],\n",
       "       [-2.01376798e+01,  5.91221505e+01,  1.30303238e+02, ...,\n",
       "        -5.36260845e+01, -7.60163316e+00,  1.79734167e+02],\n",
       "       ...,\n",
       "       [-1.39637447e+01,  2.76800045e+01, -9.91592173e-02, ...,\n",
       "        -2.79628069e+01, -1.12852966e+01,  1.77993376e+01],\n",
       "       [-4.35520784e+00,  5.69531574e+00,  6.75323993e+00, ...,\n",
       "        -6.08904045e+00,  2.29433093e+00,  1.00694237e+01],\n",
       "       [-8.89013666e+00,  6.28166851e+00, -5.81385224e+00, ...,\n",
       "        -4.23384561e+00, -3.51962592e+00, -5.14883912e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#docvs = conceptnet_docvs\n",
    "docvs = google_docvs\n",
    "docvs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bf6188",
   "metadata": {},
   "source": [
    "`numpy` normalization procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb8253e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of normalized matrix is (2992, 300).\n",
      "Sum of normalized matrix is -2821.8530565127417.\n",
      "Max=0.26247709861429375; Min=-0.24015063773379133.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2992, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative normalization procedure\n",
    "row_sums = docvs.sum(axis=1)\n",
    "np_docvs_norm = (docvs / np.sqrt((docvs ** 2).sum(-1))[..., np.newaxis]).astype('float')\n",
    "print(\"Shape of normalized matrix is {}.\".format(np_docvs_norm.shape))\n",
    "print(\"Sum of normalized matrix is {}.\".format(np.sum(np_docvs_norm)))\n",
    "print(\"Max={}; Min={}.\".format(np.max(np_docvs_norm), np.min(np_docvs_norm)))\n",
    "np.savez(PATH_TO_DATA/'np_docvs_norm.npz', np_docvs_norm)\n",
    "np_docvs_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000911c",
   "metadata": {},
   "source": [
    "`sklearn` normalization procedure (axis=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b28e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn normalization procedure (axis=1)\n",
    "sk_docvs_norm = normalize(docvs)\n",
    "print(\"Shape of normalized matrix is {}.\".format(sk_docvs_norm.shape))\n",
    "print(\"Sum of normalized matrix is {}.\".format(np.sum(sk_docvs_norm)))\n",
    "print(\"Max={}; Min={}.\".format(np.max(sk_docvs_norm), np.min(sk_docvs_norm)))\n",
    "np.savez(PATH_TO_DATA/'sk_docvs_norm.npz', sk_docvs_norm)\n",
    "sk_docvs_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded9e46",
   "metadata": {},
   "source": [
    "`sklearn` normalization procedure (axis=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn normalization procedure (axis=0)\n",
    "sk_docvs_norm_0 = normalize(docvs, axis=0)\n",
    "print(\"Shape of normalized matrix is {}.\".format(sk_docvs_norm_0.shape))\n",
    "print(\"Sum of normalized matrix is {}.\".format(np.sum(sk_docvs_norm_0)))\n",
    "print(\"Max={}; Min={}.\".format(np.max(sk_docvs_norm_0), np.min(sk_docvs_norm_0)))\n",
    "np.savez(PATH_TO_DATA/'sk_docvs_norm_0.npz', sk_docvs_norm_0)\n",
    "sk_docvs_norm_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5712f297",
   "metadata": {},
   "source": [
    "Computation of the distance matrix.\n",
    "The simple dot product is used between the matrix and its transpose.\n",
    "Here are used `scipy.sparse` matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee5180-2a9b-40bb-9105-843e378effe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sparse.csr_matrix(sk_docvs_norm_0)\n",
    "s_t = sparse.csr_matrix(sk_docvs_norm_0).T\n",
    "s_dist = s.dot(s_t)\n",
    "dists_triu = sparse.triu(s_dist, k=1)\n",
    "dists_triu = np.array(dists_triu.todense())\n",
    "np.savetxt(PATH_TO_DATA/'dists_triu.csv', dists_triu, delimiter=',')\n",
    "dists_triu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef580f77-00d7-45e0-bf22-09cc085e1c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of similarity matrix is (2992, 2992).\n",
      "Sum of similarity matrix is 2725212.7520491164.\n",
      "Max=1.0000000000000004; Min=-0.4190984022529244.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.71497394, 0.50444967, ..., 0.66298975, 0.61015226,\n",
       "        0.65692472],\n",
       "       [0.        , 0.        , 0.46490303, ..., 0.64113891, 0.7083136 ,\n",
       "        0.63537908],\n",
       "       [0.        , 0.        , 0.        , ..., 0.57545389, 0.56454262,\n",
       "        0.46803413],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.65108241,\n",
       "        0.57432244],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.59058211],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = np.dot(np_docvs_norm, np_docvs_norm.T).astype('float')\n",
    "dists_triu = np.triu(dists, k=1)\n",
    "np.savetxt('../data/dists_triu.csv', dists_triu, delimiter=',')\n",
    "print(\"Shape of similarity matrix is {}.\".format(dists_triu.shape))\n",
    "print(\"Sum of similarity matrix is {}.\".format(np.sum(dists_triu)))\n",
    "print(\"Max={}; Min={}.\".format(np.max(dists_triu), np.min(dists_triu)))\n",
    "dists_triu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40624608",
   "metadata": {},
   "source": [
    "These methods, used for building the graph, have been extracted and adapted from [this repo](https://github.com/elisamussumeci/modeling-news-spread)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad79ef81-343c-4ff8-abf8-44c3ebc17b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T16:32:36.476447Z",
     "start_time": "2022-01-08T16:32:36.427851Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_index(data, timestamp, similarities, max_dt, min_similarity, outs):\n",
    "    while True:\n",
    "        # get the maximum similarity w.r.t. older articles\n",
    "        similarity = max(similarities)\n",
    "        # get the index of such max similar article\n",
    "        index = similarities.index(similarity)\n",
    "        # get dt in terms of hours\n",
    "        dt = (timestamp - data['timestamp'][index]).total_seconds() / 3600\n",
    "        # similarity threshold\n",
    "        if similarity < min_similarity:\n",
    "            # return None to add index to outs\n",
    "            return None\n",
    "        # continue if article is in outs or its distant in time\n",
    "        elif index in outs or dt > max_dt:\n",
    "            similarities[index] = 0\n",
    "        # pass condition\n",
    "        else:\n",
    "            return index\n",
    "\n",
    "def create_graph(\n",
    "    dists_triu, # similarity matrix\n",
    "    data, # DataFrame containing articles info\n",
    "    time_max: int = 168, # max dt (in hours) for two articles to be linked\n",
    "    sim_min: float = 0.8, # minimum cos sim distance for two articles to be linked\n",
    "    ):\n",
    "    # max number of nodes\n",
    "    n_articles = dists_triu.shape[0]\n",
    "    # instantiate the directed graph\n",
    "    G = nx.DiGraph()\n",
    "    # adding the first node\n",
    "    G.add_nodes_from([(0, {\n",
    "        'step': 0,\n",
    "        'timestamp': data['timestamp'][0],\n",
    "        'source': data['source'][0],\n",
    "        'id': data['article_id'][0],\n",
    "    })])\n",
    "    # instatiating elimination list\n",
    "    outs = []\n",
    "    # loop on the other articles\n",
    "    for i in range(1, n_articles):\n",
    "        # get time of current article\n",
    "        pub_i = data['timestamp'][i]\n",
    "        # get similarities\n",
    "        column = list(dists_triu[:, i])\n",
    "        # get index of an article related to the current one\n",
    "        index = get_index(data, pub_i, column, time_max, sim_min, outs)\n",
    "        # if a relation was found\n",
    "        if index != None:\n",
    "            # if the related article has not already been inserted, insert it\n",
    "            if index not in G.nodes():\n",
    "                G.add_nodes_from([(index, {\n",
    "                    'timestamp': data['timestamp'][index],\n",
    "                    'source': data['source'][index],\n",
    "                    'id': data['article_id'][index],\n",
    "                })])\n",
    "            # if the current article has not already been inserted, insert it\n",
    "            if i not in G.nodes():\n",
    "                G.add_nodes_from([(i, {\n",
    "                    'timestamp': data['timestamp'][i],\n",
    "                    'source': data['source'][i],\n",
    "                    'id': data['article_id'][i]\n",
    "                })])\n",
    "            # linking the nodes\n",
    "            G.add_edge(index, i)\n",
    "        # if a relation wa not found\n",
    "        else:\n",
    "            # add current article to elimination listS\n",
    "            outs.append(i)\n",
    "    # return the graph\n",
    "    return G\n",
    "\n",
    "def create_matrix_domain(graph):\n",
    "    \n",
    "    domain_list = []\n",
    "    for_domain = tqdm(\n",
    "        graph.nodes(),\n",
    "        leave=False,\n",
    "        unit='nodes_for_domain',\n",
    "    )\n",
    "    for pos in for_domain:\n",
    "        node = graph.nodes()._nodes[pos]\n",
    "        d = node['source']\n",
    "        if d not in domain_list:\n",
    "            domain_list.append(d)\n",
    "\n",
    "    df = pd.DataFrame(0, index = domain_list, columns = domain_list)\n",
    "    \n",
    "    for_nodes = tqdm(\n",
    "        graph.nodes(),\n",
    "        leave=False,\n",
    "        unit='nodes',\n",
    "    )\n",
    "    \n",
    "    for pos in for_nodes:\n",
    "        node = graph.nodes()._nodes[pos]\n",
    "        d = node['source']\n",
    "        successors = graph.successors(pos)\n",
    "        for suc in successors:\n",
    "            df[d][graph.nodes()._nodes[suc]['source']] += 1\n",
    "\n",
    "    return [domain_list, df]\n",
    "\n",
    "def create_complete_adjacency(graph, matrix):\n",
    "    df = pd.DataFrame(0, index=graph.nodes(), columns=graph.nodes())\n",
    "    \n",
    "    for_nodes = tqdm(\n",
    "        graph.nodes(),\n",
    "        leave=False,\n",
    "        unit='nodes',\n",
    "    )\n",
    "    \n",
    "    for column in for_nodes:\n",
    "        i_domains_column = matrix[graph.nodes()._nodes[column]['source']]\n",
    "        for row in graph.nodes():\n",
    "            prob = i_domains_column[graph.nodes()._nodes[row]['source']]\n",
    "            df[column][row] = prob\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2772fc",
   "metadata": {},
   "source": [
    "Creating, saving and drawing the Graphs instatiated using _networkX_ library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc06e015-eb6f-4088-9e70-b83ace836917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T16:32:39.201018Z",
     "start_time": "2022-01-08T16:32:39.189349Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24467/3011287971.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  articles = articles.drop('Unnamed: 0', 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1816056005</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>537508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1816132855</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>4452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1816195886</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>267703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1816238212</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>100063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1816336438</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>23539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>1843892109</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>38907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>1843827906</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>368186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>1843729662</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>157349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>1843976290</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>158115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>1843855200</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>134909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2992 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id  timestamp  source\n",
       "0     1816056005 2021-01-06  537508\n",
       "1     1816132855 2021-01-06    4452\n",
       "2     1816195886 2021-01-06  267703\n",
       "3     1816238212 2021-01-06  100063\n",
       "4     1816336438 2021-01-06   23539\n",
       "...          ...        ...     ...\n",
       "2987  1843892109 2021-02-05   38907\n",
       "2988  1843827906 2021-02-05  368186\n",
       "2989  1843729662 2021-02-05  157349\n",
       "2990  1843976290 2021-02-05  158115\n",
       "2991  1843855200 2021-02-05  134909\n",
       "\n",
       "[2992 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pd.read_csv(PATH_TO_DATA/ARTICLES_DF_FILENAME)\n",
    "articles['timestamp'] = pd.to_datetime(articles.timestamp)\n",
    "articles = articles.drop('Unnamed: 0', 1)\n",
    "articles = articles.rename(columns={'id': 'article_id'})\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70f97f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = create_graph(dists_triu, articles, time_max=TIME_THRESHOLD, sim_min=MIN_SIM)\n",
    "nx.write_gpickle(G, PATH_TO_DATA/'empirical_graph.gpickle')\n",
    "# nx.draw(G, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f2e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dict(G.nodes())).transpose().to_csv(PATH_TO_DATA/'empirical_graph_nodes.csv')\n",
    "all_nodes_domains = []\n",
    "for i in G.nodes():\n",
    "    all_nodes_domains.append(G.nodes()._nodes[i]['source'])\n",
    "\n",
    "f = open(PATH_TO_DATA/'graph_original_domains_each_node.txt', 'w')\n",
    "for item in all_nodes_domains:\n",
    "    f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aa14860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>2981</th>\n",
       "      <th>2982</th>\n",
       "      <th>2983</th>\n",
       "      <th>2984</th>\n",
       "      <th>2985</th>\n",
       "      <th>2986</th>\n",
       "      <th>2987</th>\n",
       "      <th>2989</th>\n",
       "      <th>2990</th>\n",
       "      <th>2991</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2593 rows × 2593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     4     5     7     9     10    12    15    16    17    ...  2981  \\\n",
       "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4        1     0     0     0     0     1     0     0     0     0  ...     0   \n",
       "5        0     1     0     0     0     0     0     0     0     0  ...     0   \n",
       "7        0     1     0     0     0     0     0     0     0     0  ...     0   \n",
       "9        0     1     0     0     0     0     0     0     0     0  ...     0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "2986     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2987     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2989     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2990     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2991     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "      2982  2983  2984  2985  2986  2987  2989  2990  2991  \n",
       "0        0     0     0     0     0     0     0     0     0  \n",
       "4        0     0     0     0     0     0     0     0     0  \n",
       "5        0     0     0     0     0     0     0     0     0  \n",
       "7        0     0     0     0     0     0     0     0     0  \n",
       "9        0     0     0     0     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2986     0     0     0     0     3     0     0     0     0  \n",
       "2987     0     0     0     0     0     0     0     0     0  \n",
       "2989     0     0     0     0     0     0     0     0     0  \n",
       "2990     0     0     0     0     0     0     0     0     0  \n",
       "2991     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[2593 rows x 2593 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_list, domain_matrix = create_matrix_domain(G)\n",
    "graph_complete = create_complete_adjacency(G, domain_matrix)\n",
    "as_numpy = np.array(graph_complete)\n",
    "np.fill_diagonal(as_numpy, 0)\n",
    "np.savetxt(PATH_TO_DATA/'graph_complete.csv', as_numpy, delimiter=',')\n",
    "graph_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce8b5a-7485-4b1f-9135-8b81315daa8e",
   "metadata": {},
   "source": [
    "Methods for initializing the dynamic simulation and creating the initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52329600-96d4-41c3-b639-1f86db11f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_first_pubs(original_graph):\n",
    "    dates_list = [original_graph.nodes()[node]['timestamp'] for node in original_graph.nodes()]\n",
    "    fs = []\n",
    "    print(min(dates_list).date())\n",
    "    for node in original_graph.nodes():\n",
    "        if original_graph.nodes()[node]['timestamp'].date() == min(dates_list).date():\n",
    "            fs.append(original_graph.nodes()[node]['source'])\n",
    "    return fs\n",
    "\n",
    "\n",
    "def create_i0(list_first_pubs, domains):\n",
    "    i0 = np.zeros(len(domains))\n",
    "    for pos, i in enumerate(i0):\n",
    "        if domains[pos] in list_first_pubs:\n",
    "            i0[pos] = 1\n",
    "            list_first_pubs.remove(domains[pos])\n",
    "\n",
    "    return i0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f3bbf-1d99-4d1c-91f8-35b2914a2228",
   "metadata": {},
   "source": [
    "Retrieve initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a11ba63f-3247-4ba5-858e-68a991a491b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_first_pubs = create_first_pubs(G)\n",
    "len(list_first_pubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70fa1356-be46-4185-b420-6182442e4151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of inital infected is 127.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I0 = create_i0(list_first_pubs, all_nodes_domains)\n",
    "np.savetxt(PATH_TO_DATA/'i0.csv', I0, delimiter=',')\n",
    "print('The number of inital infected is {}'.format(np.sum(I0)))\n",
    "I0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a92361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

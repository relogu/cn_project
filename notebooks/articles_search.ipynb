{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search the articles\n",
    "\n",
    "This notebook will search the articles for the project exploiting the [Media Cloud](https://mediacloud.org/) database.\n",
    "One have to set the customizable parameters:\n",
    "\n",
    "1. `PATH_TO_DATA` is the Path object for saving the constructed DataFrames;\n",
    "2. `MY_KEY` parameter is the user key every Media Cloud user has been provided once signed up, for more info go [here](https://github.com/mediacloud/backend/blob/master/doc/api_2_0_spec/api_2_0_spec.md#authentication);\n",
    "3. `MIN_LEGTH` parameter is the minimiun length that a word must have to be considered for the word vector;\n",
    "4. `MIN_FREQUENCY` parameter is the minimum frequency a word must appear in at least one article to be considered for the word vector;\n",
    "5. `MAX_ARTICLES` parameter set the maximum number of articles to search;\n",
    "6. `N_THREADS` parameter set the number of threads for parallelizing some of the procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "\n",
    "# Constants, NOT TO BE CHANGED\n",
    "MEDIA_CLOUD_URL = 'https://api.mediacloud.org'\n",
    "STORIES_SINGLE = '/api/v2/stories_public/single/'\n",
    "STORIES_WORD_MATRIX = '/api/v2/stories_public/word_matrix/'\n",
    "# These following have to be customized\n",
    "PATH_TO_DATA = Path('../data')\n",
    "MY_KEY = '66aa9cf8dbd642b0e47f6811764cbe451a84d9429b8d2b3647c97c0af8fd40f5'\n",
    "MIN_LENGTH = 0\n",
    "MIN_FREQUENCY = 10\n",
    "MAX_ARTICLES = 3000\n",
    "N_THREADS = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will run the query that will get the word matrix (used in the project).\n",
    "One has to customize the filters for getting what he/she is interested in.\n",
    "Remind that the epidemic model works fine for events that have a rapid spreading (popular, interesting) and then die, because of that one has to pay attention not only to the argument but also to the time windows.\n",
    "For more info about constructing the query look [here](https://github.com/mediacloud/backend/blob/master/doc/api_2_0_spec/api_2_0_spec.md#query-parameters-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# Initialize articles' ids list\n",
    "stories_id = []\n",
    "# Filter to pass to the query\n",
    "params = {\n",
    "    # numer of articles per query\n",
    "    'rows': MAX_ARTICLES,\n",
    "    # filtering the language of the article to have consistent words\n",
    "    'q': 'capitol hill assault',\n",
    "    # main filters: arguments and so on\n",
    "    'fq': 'publish_date:[2021-01-05T23:59:59.999Z TO 2021-04-05T23:59:59.999Z]',\n",
    "    # personal key to pass to the query\n",
    "    'key': MY_KEY,\n",
    "}\n",
    "end = time.time()\n",
    "print('Build request, overall time elapsed: {}'.format(end - start))\n",
    "# Get word matrix of the query\n",
    "r = requests.get(\n",
    "    MEDIA_CLOUD_URL+STORIES_WORD_MATRIX,\n",
    "    params=params,\n",
    "    headers={'Accept': 'application/json'})\n",
    "end = time.time()\n",
    "print('Sent and retrieved request, overall time elapsed: {}'.format(end - start))\n",
    "# Retrieve the results to be analyzed\n",
    "stories_word_info = r.json()\n",
    "print('Found {} articles'.format(len(stories_word_info)))\n",
    "end = time.time()\n",
    "print('Overall time elapsed: {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_word_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will build the words vector DataFrame using `pandas` library.\n",
    "The DataFrame will have a column (`id`) with the id of the article, and also one column per word named with that word.\n",
    "For 3k articles this should take TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame()\n",
    "n_words = len(stories_word_info['word_list'])\n",
    "columns = [stories_word_info['word_list'][i][0] for i in range(len(stories_word_info['word_list']))]\n",
    "columns.insert(0,'article_id')\n",
    "keys_iterator = tqdm(\n",
    "    stories_word_info['word_matrix'].keys(),\n",
    "    leave=True,\n",
    "    unit='articles',\n",
    ")\n",
    "def process(key):\n",
    "    word_vector_dict = stories_word_info['word_matrix'][key]\n",
    "    word_vector = np.zeros(n_words)\n",
    "    for kkey in word_vector_dict.keys():\n",
    "        word_vector[eval(kkey)] = word_vector_dict[kkey]\n",
    "    word_vector = list([key])+list(word_vector)\n",
    "    return pd.DataFrame([word_vector], columns=columns)\n",
    "    \n",
    "results = Parallel(n_jobs=N_THREADS)(delayed(process)(i) for i in keys_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.concat(results, axis=0).reset_index().drop('index', 1).drop('level_0', 1)\n",
    "#del results\n",
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will drop out the column corresponding to the word that should not be counted for the words vectors as set by the parameters `MIN_LENGTH` and `MIN_FREQUENCY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_iterator = tqdm(\n",
    "    words_df.columns[1:],\n",
    "    leave=True,\n",
    "    unit='columns',\n",
    ")\n",
    "\n",
    "special_characters = \".\\!@#$%^&*()+?_=,<>/\"\n",
    "\n",
    "def has_numbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def has_special_chars(inputString):\n",
    "    return any(c in special_characters for c in inputString)\n",
    "\n",
    "def process_drop(col):\n",
    "    tmp = pd.to_numeric(words_df[col])\n",
    "    #if len(col) < MIN_LENGTH or len(tmp[tmp>0]) == 0 or has_numbers(col) or has_special_chars(col):\n",
    "    if has_numbers(col) or has_special_chars(col):\n",
    "        return col\n",
    "    \n",
    "cols = Parallel(n_jobs=N_THREADS)(delayed(process_drop)(i) for i in cols_iterator)\n",
    "#cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x for x in cols if (str(x) != 'nan' and str(x) != 'NaN' and str(x) != '' and str(x) != 'None')]\n",
    "words_df = words_df.drop(cols, 1)\n",
    "#del cols\n",
    "#words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will build the article info DataFrame using `pandas` library.\n",
    "Data about articles will be extracted by usign a query to Media Cloud for the single story.\n",
    "The DataFrame will have a column (`id`) with the id of the article.\n",
    "Column `timestamp` will carry the data in which the article has been published.\n",
    "Columns `source` will carry the media id of the media in which the article has been published.\n",
    "It is necessary to reordering in cronological order the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_id_iterator = tqdm(\n",
    "    words_df['article_id'],\n",
    "    leave=True,\n",
    "    unit='columns',\n",
    ")\n",
    "def process_info(article_id):\n",
    "    r = requests.get(\n",
    "        MEDIA_CLOUD_URL+STORIES_SINGLE+str(article_id),\n",
    "        params={'key': MY_KEY},\n",
    "        headers={'Accept': 'application/json'}\n",
    "    )\n",
    "    story = r.json()[0]\n",
    "    return pd.DataFrame(\n",
    "            [{\n",
    "                'article_id': article_id,\n",
    "                'timestamp': str(story['publish_date'])[:10],\n",
    "                'source': story['media_id'],\n",
    "            }]\n",
    "        )\n",
    "articles_info = Parallel(n_jobs=N_THREADS)(delayed(process_info)(i) for i in article_id_iterator)\n",
    "#articles_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.concat(articles_info, axis=0).reset_index().drop('index', 1)\n",
    "info_df['timestamp'] = pd.to_datetime(info_df.timestamp)\n",
    "info_df = info_df.sort_values(by='timestamp')\n",
    "#del articles_info\n",
    "#info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same order must be given to the other DataFrame obviously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = words_df.reindex(info_df.index.tolist())\n",
    "#words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the DataFrames are save in the data folder, defined by `PATH_TO_DATA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.to_csv(PATH_TO_DATA/'words_dataframe.csv')\n",
    "info_df.to_csv(PATH_TO_DATA/'info_dataframe.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd1e9c94448b615a760bc9c3cf750b36b9ab9a397ea85ba08ac48711d7818835"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search the articles\n",
    "\n",
    "This notebook will search the articles for the project exploiting the [Media Cloud](https://mediacloud.org/) database.\n",
    "One have to set the customizable parameters:\n",
    "\n",
    "1. `PATH_TO_DATA` is the Path object for saving the constructed DataFrames;\n",
    "2. `MY_KEY` parameter is the user key every Media Cloud user has been provided once signed up, for more info go [here](https://github.com/mediacloud/backend/blob/master/doc/api_2_0_spec/api_2_0_spec.md#authentication);\n",
    "3. `MIN_LEGTH` parameter is the minimiun length that a word must have to be considered for the word vector;\n",
    "4. `MIN_FREQUENCY` parameter is the minimum frequency a word must appear in at least one article to be considered for the word vector;\n",
    "5. `MAX_ARTICLES` parameter set the maximum number of articles to search;\n",
    "6. `N_THREADS` parameter set the number of threads for parallelizing some of the procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Constants, NOT TO BE CHANGED\n",
    "MEDIA_CLOUD_URL = 'https://api.mediacloud.org'\n",
    "STORIES_SINGLE = '/api/v2/stories_public/single/'\n",
    "STORIES_WORD_MATRIX = '/api/v2/stories_public/word_matrix/'\n",
    "# These following have to be customized\n",
    "PATH_TO_DATA = Path('../data')\n",
    "MY_KEY = '66aa9cf8dbd642b0e47f6811764cbe451a84d9429b8d2b3647c97c0af8fd40f5'\n",
    "MIN_LENGTH = 10\n",
    "MIN_FREQUENCY = 10\n",
    "MAX_ARTICLES = 3000\n",
    "N_THREADS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will run the query that will get the word matrix (used in the project).\n",
    "One has to customize the filters for getting what he/she is interested in.\n",
    "Remind that the epidemic model works fine for events that have a rapid spreading (popular, interesting) and then die, because of that one has to pay attention not only to the argument but also to the time windows.\n",
    "For more info about constructing the query look [here](https://github.com/mediacloud/backend/blob/master/doc/api_2_0_spec/api_2_0_spec.md#query-parameters-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 articles\n",
      "Found 2 articles\n",
      "Found 2 articles\n",
      "Found 2 articles\n",
      "Found 2 articles\n",
      "Found 2 articles\n",
      "Found 2 articles\n",
      "Found 2 articles\n",
      "995 ms ± 82.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Initialize articles' ids list\n",
    "stories_id = []\n",
    "# Filter to pass to the query\n",
    "params = {\n",
    "    # numer of articles per query\n",
    "    'rows': MAX_ARTICLES,\n",
    "    # filtering the language of the article to have consistent words\n",
    "    'q': 'capitol hill assault',\n",
    "    # main filters: arguments and so on\n",
    "    'fq': 'publish_date:[2021-01-05T23:59:59.999Z TO 2021-04-05T23:59:59.999Z]',\n",
    "    # personal key to pass to the query\n",
    "    'key': MY_KEY,\n",
    "}\n",
    "# Get word matrix of the query\n",
    "r = requests.get(\n",
    "    MEDIA_CLOUD_URL+STORIES_WORD_MATRIX,\n",
    "    params=params,\n",
    "    headers={'Accept': 'application/json'})\n",
    "# Retrieve the results to be analyzed\n",
    "stories_word_info = r.json()\n",
    "print('Found {} articles'.format(len(stories_word_info)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will build the words vector DataFrame using `pandas` library.\n",
    "The DataFrame will have a column (`id`) with the id of the article, and also one column per word named with that word.\n",
    "For 3k articles this should take TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2233.79keys/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>twitter</th>\n",
       "      <th>photo</th>\n",
       "      <th>awami</th>\n",
       "      <th>globe</th>\n",
       "      <th>asia</th>\n",
       "      <th>brad</th>\n",
       "      <th>mission</th>\n",
       "      <th>critic</th>\n",
       "      <th>share</th>\n",
       "      <th>...</th>\n",
       "      <th>spread</th>\n",
       "      <th>governor</th>\n",
       "      <th>week</th>\n",
       "      <th>800,000</th>\n",
       "      <th>risk-avers</th>\n",
       "      <th>congress</th>\n",
       "      <th>mlb</th>\n",
       "      <th>philip</th>\n",
       "      <th>nonprofit</th>\n",
       "      <th>unfortun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1865247844</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1873690975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1897917137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 449 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  twitter  photo  awami  globe  asia  brad  mission  critic  \\\n",
       "0  1865247844      1.0    1.0    1.0    1.0   1.0   1.0      3.0     1.0   \n",
       "1  1873690975      0.0    0.0    0.0    0.0   0.0   0.0      1.0     0.0   \n",
       "2  1897917137      0.0    0.0    0.0    0.0   0.0   0.0      0.0     1.0   \n",
       "\n",
       "   share  ...  spread  governor  week  800,000  risk-avers  congress  mlb  \\\n",
       "0    1.0  ...     0.0       0.0   0.0      0.0         0.0       0.0  0.0   \n",
       "1    0.0  ...     0.0       0.0   0.0      0.0         0.0       0.0  0.0   \n",
       "2    0.0  ...     1.0       1.0   1.0      1.0         1.0       1.0  1.0   \n",
       "\n",
       "   philip  nonprofit  unfortun  \n",
       "0     0.0        0.0       0.0  \n",
       "1     0.0        0.0       0.0  \n",
       "2     1.0        1.0       1.0  \n",
       "\n",
       "[3 rows x 449 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df = pd.DataFrame()\n",
    "n_words = len(stories_word_info['word_list'])\n",
    "columns = [stories_word_info['word_list'][i][0] for i in range(len(stories_word_info['word_list']))]\n",
    "columns.insert(0,'article_id')\n",
    "keys_iterator = tqdm(\n",
    "    stories_word_info['word_matrix'].keys(),\n",
    "    leave=True,\n",
    "    unit='keys',\n",
    ")\n",
    "def process(key):\n",
    "    word_vector_dict = stories_word_info['word_matrix'][key]\n",
    "    word_vector = np.zeros(n_words)\n",
    "    for kkey in word_vector_dict.keys():\n",
    "        word_vector[eval(kkey)] = word_vector_dict[kkey]\n",
    "    word_vector = list([key])+list(word_vector)\n",
    "    return pd.DataFrame([word_vector], columns=columns)\n",
    "    \n",
    "results = Parallel(n_jobs=N_THREADS)(delayed(process)(i) for i in keys_iterator)\n",
    "words_df = pd.concat(results, axis=0).reset_index().drop('index', 1)\n",
    "del results\n",
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will drop out the column corresponding to the word that should not be counted for the words vectors as set by the parameters `MIN_LENGTH` and `MIN_FREQUENCY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 448/448 [00:00<00:00, 3148.53columns/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>twitter</th>\n",
       "      <th>photo</th>\n",
       "      <th>awami</th>\n",
       "      <th>globe</th>\n",
       "      <th>asia</th>\n",
       "      <th>brad</th>\n",
       "      <th>mission</th>\n",
       "      <th>critic</th>\n",
       "      <th>share</th>\n",
       "      <th>...</th>\n",
       "      <th>spread</th>\n",
       "      <th>governor</th>\n",
       "      <th>week</th>\n",
       "      <th>800,000</th>\n",
       "      <th>risk-avers</th>\n",
       "      <th>congress</th>\n",
       "      <th>mlb</th>\n",
       "      <th>philip</th>\n",
       "      <th>nonprofit</th>\n",
       "      <th>unfortun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1865247844</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1873690975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1897917137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 449 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  twitter  photo  awami  globe  asia  brad  mission  critic  \\\n",
       "0  1865247844      1.0    1.0    1.0    1.0   1.0   1.0      3.0     1.0   \n",
       "1  1873690975      0.0    0.0    0.0    0.0   0.0   0.0      1.0     0.0   \n",
       "2  1897917137      0.0    0.0    0.0    0.0   0.0   0.0      0.0     1.0   \n",
       "\n",
       "   share  ...  spread  governor  week  800,000  risk-avers  congress  mlb  \\\n",
       "0    1.0  ...     0.0       0.0   0.0      0.0         0.0       0.0  0.0   \n",
       "1    0.0  ...     0.0       0.0   0.0      0.0         0.0       0.0  0.0   \n",
       "2    0.0  ...     1.0       1.0   1.0      1.0         1.0       1.0  1.0   \n",
       "\n",
       "   philip  nonprofit  unfortun  \n",
       "0     0.0        0.0       0.0  \n",
       "1     0.0        0.0       0.0  \n",
       "2     1.0        1.0       1.0  \n",
       "\n",
       "[3 rows x 449 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_iterator = tqdm(\n",
    "    words_df.columns[1:],\n",
    "    leave=True,\n",
    "    unit='columns',\n",
    ")\n",
    "\n",
    "def process_drop(col):\n",
    "    tmp = pd.to_numeric(words_df[col])\n",
    "    if len(col) < MIN_LENGTH or len(tmp[tmp>0]) == 0:\n",
    "        return col\n",
    "    \n",
    "cols = Parallel(n_jobs=N_THREADS)(delayed(process_drop)(i) for i in cols_iterator)\n",
    "cols = [x for x in cols if (str(x) != 'nan' and str(x) != 'NaN' and str(x) != '' and str(x) != 'None')]\n",
    "words_df.drop(cols, 1)\n",
    "del cols\n",
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will build the article info DataFrame using `pandas` library.\n",
    "Data about articles will be extracted by usign a query to Media Cloud for the single story.\n",
    "The DataFrame will have a column (`id`) with the id of the article.\n",
    "Column `timestamp` will carry the data in which the article has been published.\n",
    "Columns `source` will carry the media id of the media in which the article has been published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 4022.67columns/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1865247844</td>\n",
       "      <td>2021-02-27</td>\n",
       "      <td>320927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1873690975</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>179329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1897917137</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>77362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id   timestamp  source\n",
       "0  1865247844  2021-02-27  320927\n",
       "1  1873690975  2021-03-08  179329\n",
       "2  1897917137  2021-04-05   77362"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_id_iterator = tqdm(\n",
    "    words_df['article_id'],\n",
    "    leave=True,\n",
    "    unit='columns',\n",
    ")\n",
    "def process_info(article_id):\n",
    "    r = requests.get(\n",
    "        MEDIA_CLOUD_URL+STORIES_SINGLE+str(article_id),\n",
    "        params={'key': MY_KEY},\n",
    "        headers={'Accept': 'application/json'}\n",
    "    )\n",
    "    story = r.json()[0]\n",
    "    return pd.DataFrame(\n",
    "            [{\n",
    "                'id': article_id,\n",
    "                'timestamp': str(story['publish_date'])[:10],\n",
    "                'source': story['media_id'],\n",
    "            }]\n",
    "        )\n",
    "articles_info = Parallel(n_jobs=N_THREADS)(delayed(process_info)(i) for i in article_id_iterator)\n",
    "info_df = pd.concat(articles_info, axis=0).reset_index().drop('index', 1)\n",
    "del articles_info\n",
    "info_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the DataFrames are save in the data folder, defined by `PATH_TO_DATA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.to_csv(PATH_TO_DATA/'words_dataframe.csv')\n",
    "info_df.to_csv(PATH_TO_DATA/'info_dataframe.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd1e9c94448b615a760bc9c3cf750b36b9ab9a397ea85ba08ac48711d7818835"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('cn-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

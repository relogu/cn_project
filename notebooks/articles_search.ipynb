{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search the articles\n",
    "\n",
    "This notebook will search the articles for the project exploiting the [Media Cloud](https://mediacloud.org/) database.\n",
    "One have to set the customizable parameters:\n",
    "\n",
    "1. `PATH_TO_DATA` is the Path object for saving the constructed DataFrames;\n",
    "2. `MY_KEY` parameter is the user key every Media Cloud user has been provided once signed up, for more info go [here](https://github.com/mediacloud/backend/blob/master/doc/api_2_0_spec/api_2_0_spec.md#authentication);\n",
    "3. `MIN_LEGTH` parameter is the minimiun length that a word must have to be considered for the word vector;\n",
    "4. `MIN_FREQUENCY` parameter is the minimum frequency a word must appear in at least one article to be considered for the word vector;\n",
    "5. `MAX_ARTICLES` parameter set the maximum number of articles to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Constants, NOT TO BE CHANGED\n",
    "MEDIA_CLOUD_URL = 'https://api.mediacloud.org'\n",
    "STORIES_LIST = '/api/v2/stories_public/list/'\n",
    "STORIES_WORD_MATRIX = '/api/v2/stories_public/word_matrix/'\n",
    "# These following have to be customized\n",
    "PATH_TO_DATA = Path('../data')\n",
    "MY_KEY = '66aa9cf8dbd642b0e47f6811764cbe451a84d9429b8d2b3647c97c0af8fd40f5'\n",
    "MIN_LENGTH = 10\n",
    "MIN_FREQUENCY = 10\n",
    "MAX_ARTICLES = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will run two queries.\n",
    "The first will get the articles ID, while the second will get the word matrix (used in the project).\n",
    "One has to customize the filters for getting what he/she is interested in.\n",
    "Remind that the epidemic model works fine for events that have a rapid spreading (popular, interesting) and then die, because of that one has to pay attention not only to the argument but also to the time windows.\n",
    "For more info about constructing the query look [here](https://github.com/mediacloud/backend/blob/master/doc/api_2_0_spec/api_2_0_spec.md#query-parameters-5).\n",
    "For 3k articles this should take ~1.5min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2721 [01:08<12:56:18, 17.14s/columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize articles' ids list\n",
    "stories_id = []\n",
    "# Filter to pass to the query\n",
    "params = {\n",
    "    # numer of articles per query\n",
    "    'rows': MAX_ARTICLES,\n",
    "    # filtering the language of the article to have consistent words\n",
    "    'q': 'language:en',\n",
    "    # main filters: arguments and so on\n",
    "    'fq': 'text:Moderna AND text:vaccine AND text:covid',\n",
    "    # personal key to pass to the query\n",
    "    'key': MY_KEY,\n",
    "}\n",
    "# Get the articles id\n",
    "r = requests.get(\n",
    "    MEDIA_CLOUD_URL+STORIES_LIST,\n",
    "    params=params,\n",
    "    headers={'Accept': 'application/json'})\n",
    "# Fill articles' id list\n",
    "stories_info = r.json()\n",
    "# Get word matrix of the query\n",
    "r = requests.get(\n",
    "    MEDIA_CLOUD_URL+STORIES_WORD_MATRIX,\n",
    "    params=params,\n",
    "    headers={'Accept': 'application/json'})\n",
    "# Retrieve the results to be analyzed\n",
    "stories_word_info = r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will build the words vector DataFrame using `pandas` library.\n",
    "The DataFrame will have a column (`id`) with the id of the article, and also one column per word named with that word.\n",
    "For 3k articles this should take TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame()\n",
    "n_words = len(stories_word_info['word_list'])\n",
    "columns = [stories_word_info['word_list'][i][0] for i in range(len(stories_word_info['word_list']))]\n",
    "columns.insert(0,'id')\n",
    "keys_iterator = tqdm(\n",
    "    stories_word_info['word_matrix'].keys(),\n",
    "    leave=True,\n",
    "    unit='columns',\n",
    ")\n",
    "def process(key):\n",
    "    word_vector_dict = stories_word_info['word_matrix'][key]\n",
    "    word_vector = np.zeros(n_words)\n",
    "    for kkey in word_vector_dict.keys():\n",
    "        word_vector[eval(kkey)] = word_vector_dict[kkey]\n",
    "    word_vector = list([key])+list(word_vector)\n",
    "    return pd.DataFrame([word_vector], columns=columns)\n",
    "    # words_df = words_df.append(pd.DataFrame([word_vector], columns=columns))\n",
    "    \n",
    "results = Parallel(n_jobs=10)(delayed(process)(i) for i in keys_iterator)\n",
    "results = pd.concat(results, axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will drop out the column corresponding to the word that should not be counted for the words vectors as set by the parameters `MIN_LENGTH` and `MIN_FREQUENCY`.\n",
    "For 3k articles this should take TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_iterator = tqdm(\n",
    "    words_df.columns,\n",
    "    leave=True,\n",
    "    unit='columns',\n",
    ")\n",
    "for col in cols_iterator:\n",
    "    if len(col) < MIN_LENGTH:\n",
    "        words_df = words_df.drop(col,1)\n",
    "        continue\n",
    "    words_df[col] = pd.to_numeric(words_df[col])\n",
    "    if len(words_df[words_df[col]>MIN_FREQUENCY]) == 0:\n",
    "        words_df = words_df.drop(col,1)\n",
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will build the article info DataFrame using `pandas` library.\n",
    "The DataFrame will have a column (`id`) with the id of the article.\n",
    "Column `timestamp` will carry the data in which the article has been published.\n",
    "Columns `source` will carry the media id of the media in which the article has been published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.DataFrame()\n",
    "info_df['id'] = [stories_info[i]['stories_id'] for i in range(len(stories_info))]\n",
    "info_df['timestamp'] = [stories_info[i]['publish_date'] for i in range(len(stories_info))]\n",
    "info_df['timestamp'] = info_df['timestamp'].map(lambda x : x[:10])\n",
    "info_df['timestamp'] = pd.to_datetime(info_df.timestamp)\n",
    "info_df['source'] = [stories_info[i]['media_id'] for i in range(len(stories_info))]\n",
    "info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the DataFrames are save in the data folder, defined by `PATH_TO_DATA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.to_csv(PATH_TO_DATA/'words_dataframe.csv')\n",
    "info_df.to_csv(PATH_TO_DATA/'info_dataframe.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd1e9c94448b615a760bc9c3cf750b36b9ab9a397ea85ba08ac48711d7818835"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('cn-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
